{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q-CZmunZgrZo"
      },
      "outputs": [],
      "source": [
        "!pip install fastai --upgrade -q\n",
        "from fastai.vision.all import *\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!pip install wwf -q\n",
        "!pip install timm -q\n",
        "from wwf.vision.timm import *\n",
        "\n",
        "!pip install efficientnet_pytorch -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_df = pd.read_csv('train_v2.csv')\n",
        "print (train_df)\n",
        "def get_x(r):\n",
        "    return path/'train-jpg'/(r['image_name']+'.jpg')\n",
        "\n",
        "def get_y(r):\n",
        "    return r['tags'].split()\n",
        "\n",
        "def get_data(size=224,bs=64,data_df=train_df):\n",
        "    dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
        "                       splitter=RandomSplitter(seed=42),\n",
        "                       get_x=get_x,\n",
        "                       get_y=get_y,\n",
        "                       item_tfms = Resize(size),\n",
        "                       batch_tfms = [*aug_transforms(flip_vert=True,max_warp=0),\n",
        "                                     Normalize.from_stats(*imagenet_stats)]\n",
        "                      )\n",
        "    return dblock.dataloaders(data_df,bs=bs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAmpkE6LjYTB",
        "outputId": "7e056e9b-7122-4133-c492-bec23338ae8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        image_name                                           tags\n",
            "0          train_0                                   haze primary\n",
            "1          train_1                agriculture clear primary water\n",
            "2          train_2                                  clear primary\n",
            "3          train_3                                  clear primary\n",
            "4          train_4      agriculture clear habitation primary road\n",
            "...            ...                                            ...\n",
            "40474  train_40474                                  clear primary\n",
            "40475  train_40475                                         cloudy\n",
            "40476  train_40476                      agriculture clear primary\n",
            "40477  train_40477                 agriculture clear primary road\n",
            "40478  train_40478  agriculture cultivation partly_cloudy primary\n",
            "\n",
            "[40479 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dls = get_data(300,40)\n",
        "dls.show_batch(nrows=1, ncols=3)"
      ],
      "metadata": {
        "id": "To8XT_49rxnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# f2macro = FBetaMulti(beta=2,average='macro')\n",
        "# f2micro = FBetaMulti(beta=2,average='micro')\n",
        "f2samples = FBetaMulti(beta=2,average='samples',thresh=0.2)\n",
        "\n",
        "# model = EfficientNet.from_pretrained('efficientnet-b7', get_c(dls))\n",
        "metrics = [partial(accuracy_multi, thresh=0.2), f2samples]\n",
        "cbs = [MixUp]\n",
        "# learn = cnn_learner(dls, resnet50, metrics=metrics, cbs=cbs)\n",
        "# learn = Learner(dls, model, metrics=metrics, f2samples], cbs=cbs)\n",
        "# learn = Learner(dls, model, metrics=metrics, loss_func=LabelSmoothingCrossEntropy(), cbs=cbs)\n",
        "\n",
        "learn = timm_learner(dls, 'efficientnet_b3', metrics=metrics, cbs=cbs)\n",
        "\n",
        "# learn.lr_find()\n",
        "learn.fine_tune(12, base_lr=3e-2, freeze_epochs=4)"
      ],
      "metadata": {
        "id": "vqiHGLZ8qze6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PH3PZhTxqUaY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}